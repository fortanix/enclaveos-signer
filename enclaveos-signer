#!/usr/bin/env python3


from cryptography.hazmat.backends import default_backend
from cryptography.hazmat.primitives.serialization import load_der_public_key, load_pem_private_key
from cryptography.hazmat.primitives.asymmetric import padding
from cryptography.hazmat.primitives.asymmetric.rsa import RSAPublicKey
from cryptography.hazmat.primitives import hashes

from sdkms.v1 import (configuration, ApiClient, ApprovalRequestsApi, AuthenticationApi, PluginsApi,
                      SecurityObjectsApi, SignAndVerifyApi, SignRequest, SobjectDescriptor,
                      SobjectRequest)
from sdkms.v1.models import ApprovalRequestRequest, ApprovalStatus, DigestAlgorithm, ObjectType
from sdkms.v1.rest import ApiException

import argparse
import base64
import binascii
import datetime
import docker
import hashlib
import io
import os
import re
import shutil
import struct
import subprocess
import sys
import tarfile
import tempfile
import time


__version__ = "0.12.651"

""" Default / Architectural Options """

ARCHITECTURE = "amd64"

PAGESIZE = 4096
MEMORY_GAP = PAGESIZE

TCSSIZE = PAGESIZE

# We may need to support larger SSA sizes for future CPUs. ZIRC-2136.
SSAFRAMESIZE = PAGESIZE
SSAFRAMENUM = 2

ENCLAVE_STACK_SIZE = PAGESIZE * 16
DEFAULT_ENCLAVE_SIZE = '256M'
DEFAULT_THREAD_NUM = 4
ENCLAVE_HEAP_MIN = 0x10000

DEFAULT_FORTANIX_API_ENDPOINT = 'https://api.amer.smartkey.io'

# This size must match the architecturally-defined sgx_arch_gpr_t in sgx-arch.h.
SGX_ARCH_GPR_SIZE = 184

verbose = False

# If you need to debug what's getting hashed, you can set mrenclave_debug to True and the signer will produce
# /tmp/mrenclave.signer with all of the input data.
mrenclave_debug = False

# This is from tools/converter/app/builder.py
IMAGE_REGEX = re.compile('^((?:[a-zA-Z0-9-.]+(?::[0-9]+)?/)?(?:[a-zA-Z0-9-_/]+))(?::([a-zA-Z0-9-._]+))?$')

""" Utilities """

def debug_print(*argv):
    if verbose:
        print(*argv, file=sys.stderr)

def roundup(addr):
    remaining = addr % PAGESIZE
    if remaining:
        return addr + (PAGESIZE - remaining)
    else:
        return addr

def rounddown(addr):
    return addr - addr % PAGESIZE

def roundup_data(data):
    return data + '\0' * (roundup(len(data)) - len(data))

def parse_int(s):
    if len(s) > 2 and s.startswith("0x"):
        return int(s[2:], 16)
    if len(s) > 1 and s.startswith("0"):
        return int(s[1:], 8)
    return int(s)

def parse_size(s):
    scale = 1
    if s.endswith("K"):
        scale = 1024
    if s.endswith("M"):
        scale = 1024 * 1024
    if s.endswith("G"):
        scale = 1024 * 1024 * 1024
    if scale != 1:
        s = s[:-1]
    return parse_int(s) * scale

def unsigned_short(inp):
    res = int(inp)
    if res < 0 or res >= pow(2,16):
         raise argparse.ArgumentTypeError("%s should be between 0 and 2^16 -1" % value)
    return res

""" Reading / Writing Manifests """

def read_manifest(filename):
    manifest = {}
    manifest_layout = []
    with open(filename, "r") as f:
        for line in f.readlines():
            if line == "":
                manifest_layout.append((None, None))
                break

            pound = line.find("#")
            if pound != -1:
                comment = line[pound:].strip()
                line = line[:pound]
            else:
                comment = None

            line = line.strip()
            equal = line.find("=")
            if equal != -1:
                key = line[:equal].strip()
                manifest[key] = line[equal + 1:].strip()
            else:
                key = None

            manifest_layout.append((key, comment))

    return (manifest, manifest_layout)

def output_manifest(filename, manifest, manifest_layout):
    with open(filename, 'w') as f:
        written = []

        for (key, comment) in manifest_layout:
            line = ''
            if key is not None:
                line += key + ' = ' + manifest[key]
                written.append(key)
            if comment is not None:
                if line != '':
                    line += ' '
                line += comment
            print(line, file=f)

        print("\n# Generated by {}\n".format("enclaveos-signer"), file=f)

        for key in sorted(manifest.keys()):
            if key not in written:
                print(key, '=', manifest[key], file=f)


""" Loading Enclave Attributes """

def get_enclave_attributes(cmdline_args):
    sgx_flags = {
        'FLAG_DEBUG'          : struct.pack("<Q", 0x02),
        'FLAG_MODE64BIT'      : struct.pack("<Q", 0x04),
    }

    sgx_xfrms = {
        'XFRM_LEGACY'         : struct.pack("<Q", 0x03),
        'XFRM_AVX'            : struct.pack("<Q", 0x06),
        'XFRM_AVX3'           : struct.pack("<Q", 0xe6),
        'XFRM_MPX'            : struct.pack("<Q", 0x18),
    }

    sgx_miscs = {
        'MISC_EXINFO'         : struct.pack("<L", 0x01),
    }

    attributes = [
        'FLAG_DEBUG',
        'FLAG_MODE64BIT',
        'XFRM_LEGACY',
        'XFRM_AVX',
    ]

    masks = [
        'FLAG_DEBUG',
        'FLAG_MODE64BIT',
    ]

    # Remove DEBUG from ATTRIBUTES, but not from ATTRIBUTEMASK.
    if cmdline_args.production:
        attributes.remove('FLAG_DEBUG')

    flags_raw = struct.pack("<Q", 0)
    flagmask_raw = struct.pack("<Q", 0)
    xfrms_raw = struct.pack("<Q", 0)
    miscs_raw = struct.pack("<L", 0)

    for attr in attributes:
        if attr in sgx_flags:
            flags_raw = bytes([a | b for a, b in zip(flags_raw, sgx_flags[attr])])
        if attr in sgx_xfrms:
            xfrms_raw = bytes([a | b for a, b in zip(xfrms_raw, sgx_xfrms[attr])])
        if attr in sgx_miscs:
            miscs_raw = bytes([a | b for a, b in zip(miscs_raw, sgx_miscs[attr])])

    for attr in masks:
        if attr in sgx_flags:
            flagmask_raw = bytes([a | b for a, b in zip(flagmask_raw, sgx_flags[attr])])

    debug_print("Attributes:")
    debug_print("    flags:     %016x" % (int.from_bytes(flags_raw, byteorder='big')))
    debug_print("    flagmask:  %016x" % (int.from_bytes(flagmask_raw, byteorder='big')))
    debug_print("    xfrms:     %016x" % (int.from_bytes(xfrms_raw, byteorder='big')))
    debug_print("    miscs:     %08x"  % (int.from_bytes(miscs_raw, byteorder='big')))

    return flags_raw, flagmask_raw, xfrms_raw, miscs_raw


""" Generate Checksums / Measurement """

def resolve_uri(uri, reader, check_exist=True):
    orig_uri = uri
    if uri.startswith('file:'):
        target = os.path.abspath(uri[5:])
    else:
        target = os.path.abspath(uri)
    if check_exist and not reader.exists(target):
        raise Exception('Cannot resolve ' + orig_uri + ' or the file does not exist.')
    return target

def get_checksum(file, reader):
    digest = hashlib.sha256()
    with open(reader.get_file(file), 'rb') as f:
        digest.update(f.read())
    return digest.digest()

def get_trusted_files(manifest, executable, reader):
    targets = {}

    # TODO: We need to rework the way that we generate the keys for the
    # trusted files. sgx.trusted.files.<filename> may not be unique if
    # there are two trusted files with the same file name but in different
    # directories.
    if 'sgx.trusted_files.exec' not in manifest:
        if executable:
            exec_output = "file:" + executable
            manifest['sgx.trusted_files.exec'] = exec_output

    runtime = reader.get_runtime_path()

    # loader.preload can specify a single shared library or executable that will be loaded instead of the shim.
    if 'loader.preload' in manifest:
        load_shim = False
        uri = manifest['loader.preload'].strip()
        targets['preload'] = (uri, resolve_uri(uri, reader))
    else:
        uri = 'file:' + os.path.join(runtime, "bootstrap",
                                     "libenclaveos-interface.so")
        # We reserve tags starting with enclaveos for internal use.
        # manifest files shouldn't use this string.
        targets["enclaveos_shim"] = (uri, resolve_uri(uri, reader))

    if 'loader.vdso' not in manifest or manifest['loader.vdso'].strip() != 'none':
        uri = 'file:' + os.path.join(runtime, "bootstrap",
                                     "libenclaveos-vdso.so")
        targets["enclaveos_vdso"] = (uri, resolve_uri(uri, reader))


    # The preload libraries have their checksums added to the SGX manifest
    # under the name sgx.trusted_checksum.preload0,
    # sgx.trusted_checksum.preload1, and so on. The code in init_trusted_files()
    # in enclave_framework.c processes the preload library list and searches
    # for the checksums in the same order.

    for (key, val) in manifest.items():
        if not key.startswith('sgx.trusted_files.'):
            continue
        key = key[len('sgx.trusted_files.'):]
        if key in targets:
            raise Exception('repeated key in manifest: sgx.trusted_files.' + key)
        targets[key] = (val, resolve_uri(val, reader))

    for (key, val) in targets.items():
        (uri, target) = val
        checksum = binascii.hexlify(get_checksum(target, reader))
        targets[key] = (uri, target, checksum)

    return targets

def get_trusted_children(manifest):
    targets = {}

    for (key, val) in manifest.items():
        if not key.startswith('sgx.trusted_children.'):
            continue
        key = key[len('sgx.trusted_children.'):]
        if key in targets:
            raise Exception('repeated key in manifest: sgx.trusted_children.' + key)

        target = resolve_uri(val, LocalFileReader())
        sig = binascii.hexlify(open(target, 'rb').read()[960:992])
        targets[key] = (val, target, sig)

    return targets

""" Populate Enclave Memory """

PAGEINFO_R = 0x1
PAGEINFO_W = 0x2
PAGEINFO_X = 0x4
PAGEINFO_TCS = 0x100
PAGEINFO_REG = 0x200

def get_loadcmds(filename):
    loadcmds = []
    # This can hang. ZIRC-2003.
    p = subprocess.Popen(['/usr/bin/readelf', '-l', '-W', filename],
                         stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    while True:
        line = p.stdout.readline().decode('utf-8')
        if line == '':
            break
        stripped = line.strip()
        if not stripped.startswith('LOAD'):
            continue
        tokens = stripped.split()
        if len(tokens) < 6:
            continue
        if len(tokens) >= 7 and tokens[7] == "E":
            tokens[6] += tokens[7]
        prot = 0
        for t in tokens[6]:
            if t == "R":
                prot = prot | 4
            if t == "W":
                prot = prot | 2
            if t == "E":
                prot = prot | 1

        loadcmds.append((int(tokens[1][2:], 16),  # offset
                         int(tokens[2][2:], 16),  # addr
                         int(tokens[4][2:], 16),  # filesize
                         int(tokens[5][2:], 16),  # memsize
                         prot))
    p.wait()
    if p.returncode != 0:
        return None
    return loadcmds

# Returns a list of dynamic symbols in the data segment of an ELF file. Returns an array of tuples of the form
# (symbol_name, load_address, symbol_size)
def get_data_symbols(filename):
    data_symbols = []
    p = subprocess.Popen(['/usr/bin/objdump', '--section', '.data', '-T', filename],
                         stdout=subprocess.PIPE)
    while True:
        line = p.stdout.readline().decode('utf-8')
        if line == '':
            break
        stripped = line.strip()
        tokens = stripped.split()
        if len(tokens) < 7:
            continue
        data_symbols.append((tokens[6], int(tokens[0], 16), int(tokens[4], 16)))
    p.kill()
    p.wait()

    return data_symbols

def get_entry_point(filename):
    p = subprocess.Popen(['/usr/bin/readelf', '-h', filename],
                         stdout=subprocess.PIPE)
    while True:
        line = p.stdout.readline().decode('utf-8')
        if line == '':
            break
        stripped = line.strip()
        match = re.search('Entry point address:\s*(0x[0-9a-fA-F]+)', line)
        if match:
            entry = int(match.group(1), 0)
            p.kill()
            p.wait()
            return entry

    assert(0)
            
class MemoryArea(object):
    def __init__(self, desc, file=None, addr=None, size=None, flags=None, eextend=None, contents=None):
        self.desc = desc
        self.file = file
        self.addr = addr
        self.size = size
        self.flags = flags
        self.is_binary = False
        self.eextend = eextend
        self.contents = contents

        if file:
            loadcmds = get_loadcmds(file)
            if loadcmds:
                mapaddr = 0xffffffffffffffff
                mapaddr_end = 0
                for (offset, addr, filesize, memsize, prot) in loadcmds:
                    if rounddown(addr) < mapaddr:
                        mapaddr = rounddown(addr)
                    if roundup(addr + memsize) > mapaddr_end:
                        mapaddr_end = roundup(addr + memsize)

                self.is_binary = True
                self.size = mapaddr_end - mapaddr
                if mapaddr > 0:
                    self.addr = mapaddr
            else:
                self.size = os.stat(file).st_size

        if self.addr is not None:
            self.addr = rounddown(self.addr)
        if self.size is not None:
            self.size = roundup(self.size)

# Create the initial contents for the SGX TCS. This has to match sgx_arch_tcs_t in sgx-arch.h.
def create_tcs(ssa_base, tls_base, pal_code_base, enclave_entry, num_threads):
    layout = bytearray(num_threads * PAGESIZE)
    for t in range(num_threads):
        reserved = 0
        flags = 0
        nssa = SSAFRAMENUM
        cssa = 0
        ossa = ssa_base + t * nssa * SSAFRAMESIZE
        fsbase = 0
        gsbase = tls_base + t * PAGESIZE
        fslimit = 0xfff
        gslimit = 0xfff

        # enclave_entry is the offset relative to the PAL base, so we need to add the actual PAL load address.
        rebased_enclave_entry = pal_code_base + enclave_entry

        tcs = struct.pack('<QQQLLQQQQLL', reserved, flags, ossa, cssa, nssa, rebased_enclave_entry, reserved,
                          fsbase, gsbase, fslimit, gslimit)
        layout[0 + t * PAGESIZE : 72 + t * PAGESIZE] = tcs

    return layout

# Create initial contents for the enclave TLS pages. This has to match struct enclave_tls in enclave-tls.h.
def create_tls(tls_base, stacks, ssa_base, num_threads):
    layout = bytearray(num_threads * PAGESIZE)
    for t in range(num_threads):
        tls_self = tls_base + PAGESIZE * t
        initial_stack = stacks[t].addr + ENCLAVE_STACK_SIZE
        fsbase = 0
        ssaframesize = SSAFRAMESIZE
        ssa = ssa_base + ssaframesize * SSAFRAMENUM * t
        gpr = ssa + ssaframesize - SGX_ARCH_GPR_SIZE
        
        tls = struct.pack('<QQQQQQ', tls_self, initial_stack, fsbase, ssaframesize, ssa, gpr)
        layout[0 + t * PAGESIZE : 48 + t * PAGESIZE] = tls
    return layout


def get_memory_areas(manifest, thread_num, libpal, vdso_path, shim_path):
    areas = []
    areas.append(MemoryArea('ssa', size=thread_num * SSAFRAMESIZE * SSAFRAMENUM,
                            flags=PAGEINFO_R|PAGEINFO_W|PAGEINFO_REG, eextend=True,
                            contents=bytes(thread_num * SSAFRAMESIZE * SSAFRAMENUM)))
    areas.append(MemoryArea('tcs', size=thread_num * TCSSIZE,
                            flags=PAGEINFO_TCS, eextend=True, contents=None))
    areas.append(MemoryArea('tls', size=thread_num * PAGESIZE,
                            flags=PAGEINFO_R|PAGEINFO_W|PAGEINFO_REG, eextend=True))

    stacks = []
    for t in range(thread_num):
        area = MemoryArea('stack', size=ENCLAVE_STACK_SIZE,
                          flags=PAGEINFO_R|PAGEINFO_W|PAGEINFO_REG, eextend=True,
                          contents=bytes(ENCLAVE_STACK_SIZE))
        areas.append(area)
        stacks.append(area)

    areas.append(MemoryArea('pal', file=libpal, flags=PAGEINFO_REG, eextend=True))

    if vdso_path is not None:
        areas.append(MemoryArea('vdso', file=vdso_path, flags=PAGEINFO_REG, eextend=True))

    if shim_path is not None:
        areas.append(MemoryArea('shim', file=shim_path, flags=PAGEINFO_REG, eextend=True))

    return (areas, stacks)

def populate_memory_areas(manifest, enclave_size, areas):
    populating = enclave_size

    for area in areas:
        if area.addr is not None:
            continue

        area.addr = populating - area.size
        if area.addr < ENCLAVE_HEAP_MIN:
            raise Exception("Enclave size is not large enough")
        if area.desc == 'exec':
            populating = area.addr;
        else:
            populating = area.addr - MEMORY_GAP

    free_areas = []
    for area in areas:
        if area.addr + area.size < populating:
            addr = area.addr + area.size
            free_areas.append(MemoryArea('free', addr=addr, size=populating - addr,
                                flags=PAGEINFO_R|PAGEINFO_W|PAGEINFO_X|PAGEINFO_REG, eextend=False))
            populating = area.addr

    if populating > ENCLAVE_HEAP_MIN:
        free_areas.append(MemoryArea('free', addr=ENCLAVE_HEAP_MIN,
                                     size=populating - ENCLAVE_HEAP_MIN,
                                     flags=PAGEINFO_R|PAGEINFO_W|PAGEINFO_X|PAGEINFO_REG, eextend=False))

    return areas + free_areas

def generate_measurement(enclave_size, areas):

    def do_ecreate(digest, size):
        data = struct.pack("<8sLQ44s", b"ECREATE", SSAFRAMESIZE // PAGESIZE, size, b"")
        digest.update(data)

    def do_eadd(digest, offset, flags):
        data = struct.pack("<8sQQ40s", b"EADD", offset, flags, b"")
        digest.update(data)

    def do_eextend(digest, offset, payload):
        data = struct.pack("<8sQ48s", b"EEXTEND", offset, b"")
        digest.update(data)
        digest.update(payload)

    class mrenclave_digest(object):
        def __init__(self):
            self.digest = hashlib.sha256()
            if mrenclave_debug:
                self.debug_handle = open("/tmp/mrenclave.signer", "wb")
            else:
                self.debug_handle = None

        def update(self, payload):
            for er in range(0, len(payload), 64):
                self.digest.update(payload[er:er+64])

            if self.debug_handle:
                self.debug_handle.write(payload)

        def finalize(self):
            return self.digest.digest()

    mrenclave = mrenclave_digest()
    do_ecreate(mrenclave, enclave_size)

    def print_area(addr, size, flags, desc, measured):
        if flags & PAGEINFO_REG:
            type = 'REG'
        if flags & PAGEINFO_TCS:
            type = 'TCS'
        prot = ['-', '-', '-']
        if flags & PAGEINFO_R:
            prot[0] = 'R'
        if flags & PAGEINFO_W:
            prot[1] = 'W'
        if flags & PAGEINFO_X:
            prot[2] = 'X'
        prot = ''.join(prot)

        desc = '(' + desc + ')'
        if measured:
            desc += ' measured'

        if size == PAGESIZE:
            debug_print("    %016x [%s:%s] %s" % (addr, type, prot, desc))
        else:
            debug_print("    %016x-%016lx [%s:%s] %s" % (addr, addr + size, type, prot, desc))

    def load_file(digest, f, offset, addr, filesize, memsize, desc, flags):
        f_addr = rounddown(offset)
        m_addr = rounddown(addr)
        f_size = roundup(offset + filesize) - f_addr
        m_size = roundup(addr + memsize) - m_addr

        print_area(m_addr, f_size, flags, desc, True)
        if f_size < m_size:
            print_area(m_addr + f_size, m_size - f_size, flags, "bss", True)

        for pg in range(m_addr, m_addr + m_size, PAGESIZE):
            do_eadd(digest, pg, flags)

            for er in range(pg, pg + PAGESIZE, 256):
                start = er - m_addr + f_addr
                end = start + 256
                start_zero = b""
                if start < offset:
                    if offset - start >= 256:
                        start_zero = bytes(256)
                    else:
                        start_zero = bytes(offset - start)
                end_zero = b""
                if end > offset + filesize:
                    if end - offset - filesize >= 256:
                        end_zero = bytes(256)
                    else:
                        end_zero = bytes(end - offset - filesize)
                start += len(start_zero)
                end -= len(end_zero)
                if start < end:
                    f.seek(start)
                    data = f.read(end - start)
                else:
                    data = b""
                if len(start_zero + data + end_zero) != 256:
                    raise Exception("wrong calculation")
                payload = start_zero + data + end_zero
                do_eextend(digest, er, payload)

    for area in areas:
        if area.file:
            with open(area.file, 'rb') as f:
                if area.is_binary:
                    loadcmds = get_loadcmds(area.file)
                    if loadcmds:
                        mapaddr = 0xffffffffffffffff
                        for (offset, addr, filesize, memsize, prot) in loadcmds:
                            if rounddown(addr) < mapaddr:
                                mapaddr = rounddown(addr)
                    baseaddr = area.addr - mapaddr
                    for (offset, addr, filesize, memsize, prot) in loadcmds:
                        flags = area.flags
                        if prot & 4:
                            flags = flags | PAGEINFO_R
                        if prot & 2:
                            flags = flags | PAGEINFO_W
                        if prot & 1:
                            flags = flags | PAGEINFO_X

                        # All loadable segments need to be writable, so we can perform
                        # relocations. When we fix ZIRC-2013 and perform the relocations
                        # before the enclave is started, we can remove this extra write
                        # permission.
                        flags = flags | PAGEINFO_W

                        if flags & PAGEINFO_X:
                            desc = 'code'
                        else:
                            desc = 'data'
                        load_file(mrenclave, f, offset, baseaddr + addr,
                                  filesize, memsize, desc, flags)
                else:
                    load_file(mrenclave, f, 0, area.addr,
                              os.stat(area.file).st_size, area.size,
                              area.desc, area.flags)
        else:
            for a in range(area.addr, area.addr + area.size, PAGESIZE):
                do_eadd(mrenclave, a, area.flags)
                if area.eextend:
                    for er in range(a, a + PAGESIZE, 256):
                        do_eextend(mrenclave, er,
                                   area.contents[er - area.addr:er + 256 - area.addr])
                
            print_area(area.addr, area.size, area.flags, area.desc, area.eextend)

    return mrenclave.finalize()

SGX_SIGNING_KEY_MODULUS_LEN = 3072
SGX_SIGNING_KEY_EXPONENT = 3

class PythonSigner(object):
    def __init__(self, key_file):
        self.key_file = key_file

    # Sign the given message. Returns tuple of message and the key's modulus.
    def sign(self, message):
        with open(self.key_file, 'rb') as f:
            key = load_pem_private_key(f.read(), password=None, backend=default_backend())

        if not isinstance(key.public_key(), RSAPublicKey):
            raise RuntimeError('The specified key is not an RSA key')
        if key.key_size != SGX_SIGNING_KEY_MODULUS_LEN:
            raise RuntimeError('The specified key has a size ({}) other than {} bits'.format(
                key.key_size, SGX_SIGNING_KEY_MODULUS_LEN))
        pub = key.public_key().public_numbers()
        if pub.e != SGX_SIGNING_KEY_EXPONENT:
            raise RuntimeError('The specified key has a public exponent ({}) other than {}'.format(
                pub.e, SGX_SIGNING_KEY_EXPONENT))
        modulus = pub.n

        signature = key.sign(bytes(message), padding.PKCS1v15(), hashes.SHA256())

        return (signature, modulus)

# pub struct SignAndLogRequest<'a> {
#     pub kid : SobjectDescriptor,
#     pub build_info : &'a str,
#     pub hash: Blob,
#     pub isvprodid: i16,
#     pub plugin: Uuid,
# }

class SignAndLogRequest(object):
    def __init__(self, kid=None, build_info=None, hash=None, isvprodid=None, plugin=None):
        self._kid = kid
        self._build_info = build_info
        self._hash = hash
        self._isvprodid = isvprodid
        self._plugin = plugin

    @property
    def kid(self):
        return self._kid

    @kid.setter
    def kid(self, kid):
        self._kid = kid

    @property
    def build_info(self):
        return self._build_info

    @build_info.setter
    def build_info(self, build_info):
        self._build_info = build_info

    @property
    def hash(self):
        return self._hash

    @hash.setter
    def hash(self, hash):
        self._hash = hash

    @property
    def isvprodid(self):
        return self._isvprodid

    @isvprodid.setter
    def isvprodid(self, isvprodid):
        self._isvprodid = isvprodid

    @property
    def plugin(self):
        return self._plugin

    @plugin.setter
    def plugin(self, plugin):
        self._plugin = plugin

    def to_dict(self):
        return {
            'kid'           : self.kid,
            'build_info'    : self.build_info,
            'hash'          : self.hash,
            'isvprodid'     : self.isvprodid,
            'plugin'        : self.plugin,
        }

# req may be anything that swagger can serialize, including a swagger model
# type or a plain dict.
#
# responses are always returned as dictionaries, because that is easier than
# trying to decode the response to the appropriate data type
def execute_maybe_approve(api_client, req, req_fn, operation, method='POST'):
    try:
        resp = req_fn(api_client, req)
        if not isinstance(resp, dict):
            return resp.to_dict()
        else:
            return resp
    except ApiException as e:
        if e.body != 'This operation requires approval':
            raise

        approval_api = ApprovalRequestsApi(api_client)
        approval_req = ApprovalRequestRequest(
            body=req,
            operation=operation,
            method=method,
            description='Quorum approval request',
        )
        resp = approval_api.create_approval_request(approval_req)
        approval_req_id = resp.request_id
        while True:
            resp = approval_api.get_approval_request(approval_req_id)
            status = resp.status
            if status == ApprovalStatus.APPROVED:
                resp = approval_api.get_result(approval_req_id)
                break
            elif status == ApprovalStatus.PENDING:
                print('Approval Pending')
                time.sleep(20)
            elif status == ApprovalStatus.FAILED:
                print(approval_api.get_result(approval_req_id))
                raise RuntimeError('Request failed')
            elif status == ApprovalStatus.DENIED:
                raise RuntimeError('Request denied')
            else:
                raise RuntimeError('Unknown status {}'.format(status)())
        if resp.status != 200:
            raise RuntimeError('Operation failed: {}'.format(resp))
        return resp.body

class SdkmsSigner(object):
    def __init__(self, key_name, isvprodid, plugin_id=None, build_info=None):
        self.key_name = key_name
        self.isvprodid = isvprodid
        self.plugin_id = plugin_id
        self.build_info = build_info

    def _client(self):
        config = configuration.Configuration()
        config.verify_ssl = not os.environ.get('FORTANIX_NO_VERIFY_SSL', False)
        config.host = os.environ.get('FORTANIX_API_ENDPOINT', DEFAULT_FORTANIX_API_ENDPOINT)
        config.app_api_key = os.environ['FORTANIX_API_KEY']

        api_client = ApiClient(configuration=config)

        auth = AuthenticationApi(api_client).authorize()

        # The swagger interface calls this type of authorization an 'apiKey'.
        # This is not related to the SDKMS notion of an API key. The swagger
        # apiKey is our auth token.
        config.api_key['Authorization'] = auth.access_token
        config.api_key_prefix['Authorization'] = 'Bearer'

        return api_client

    # Sign the given message. Returns tuple of message and the key's modulus.
    def sign(self, message):
        api_client = self._client()

        # The signed data is (0..128) and (900..1028) from the sigstruct.
        # The mrenclave is located at offset 960 in the sigstruct.
        mrenclave = message[188:220]

        hasher = hashlib.sha256()
        hasher.update(message)
        digest = hasher.digest()

        sobjs = SecurityObjectsApi(api_client).get_security_objects(name=self.key_name)
        if len(sobjs) != 1:
            raise RuntimeError('Unable to retrieve signing key information from SDKMS')
        kid = sobjs[0].kid

        sobj = SecurityObjectsApi(api_client).get_security_object(kid)
        if sobj.obj_type != ObjectType.RSA:
            raise RuntimeError('The specified SDKMS key has a type ({}) other than RSA'.format(sobj.obj_type))
        if sobj.key_size != SGX_SIGNING_KEY_MODULUS_LEN:
            raise RuntimeError('The specified key has a size ({}) other than {} bits'.format(
                sobj.key_size, SGX_SIGNING_KEY_MODULUS_LEN))
        pub = load_der_public_key(bytes(sobj.pub_key), backend=default_backend()).public_numbers()
        if pub.e != SGX_SIGNING_KEY_EXPONENT:
            raise RuntimeError('The specified key has a public exponent ({}) other than {}'.format(
                pub.e, SGX_SIGNING_KEY_EXPONENT))
        modulus = pub.n

        if self.plugin_id is not None:
            final_build_info = self.build_info
            final_build_info += 'MRENCLAVE: {}\n'.format(mrenclave.hex())
            final_build_info += 'ISVPRODID: {}\n'.format(self.isvprodid)
            # SignAndLogRequest is not a fully-functional swagger model, so we
            # have to manually convert it to something the swagger client
            # knows how to serialize with to_dict().
            req = SignAndLogRequest(kid=SobjectDescriptor(kid=kid),
                                    build_info=final_build_info,
                                    hash=bytearray(digest),
                                    isvprodid=self.isvprodid,
                                    plugin=self.plugin_id).to_dict()
            resp = execute_maybe_approve(api_client, req,
                    lambda clnt, req: PluginsApi(clnt).invoke_plugin(self.plugin_id, req),
                    '/sys/v1/plugins/{}'.format(self.plugin_id))
            signature = resp['signature']
                    
        else:
            req = SignRequest(hash=bytearray(digest), hash_alg=DigestAlgorithm.SHA256)
            resp = execute_maybe_approve(api_client, req,
                    lambda clnt, req: SignAndVerifyApi(api_client).sign(kid, req),
                    '/crypto/v1/keys/{}/sign'.format(kid))
            signature = resp['signature']

        # There are four cases to exercise in this code: (plugin, raw key)
        # crossed with (approval, no approval). In the case where we use the
        # Sign API directly and no approval is required, swagger has return
        # type information so decodes to bytearray for us. In all other cases
        # (plugin output or approvable operation output), swagger does not
        # have return type information, so gives us a base64 string.
        if not isinstance(signature, bytearray):
            signature = base64.b64decode(signature)

        return (signature, modulus)

def get_signer(cmdline_args):
    if cmdline_args.key:
        return PythonSigner(cmdline_args.key)
    elif cmdline_args.sdkms_key:
        if 'FORTANIX_API_KEY' not in os.environ:
            raise RuntimeError('You must set the FORTANIX_API_KEY environment variable to use SDKMS signing')
        if cmdline_args.build_info is not None:
            build_info = cmdline_args.build_info.read()
        else:
            build_info = ''
        return SdkmsSigner(cmdline_args.sdkms_key, cmdline_args.isvprodid, cmdline_args.plugin_id, build_info)
    else:
        raise RuntimeError('A key should have been specified on the command line')

""" Generate Sigstruct """

SIGSTRUCT_LEN = 1808

SIGSTRUCT_HEADER = (0x00000006, 0x000000e1, 0x00010000, 0x00000000)
SIGSTRUCT_VENDOR = 0
SIGSTRUCT_HEADER2 = (0x00000101, 0x00000060, 0x00000060, 0x00000001)
SIGSTRUCT_SWDEFINED = 0

def fill_sigstruct(cmdline_args, mrenclave):
    today = datetime.date.today()

    isvprodid = cmdline_args.isvprodid
    if isvprodid is None:
        isvprodid = 0
    isvsvn = cmdline_args.isvsvn
    if isvsvn is None:
        isvsvn = 0

    debug_print("ISVPRODID: %d" % (isvprodid))
    debug_print("ISVSVN:    %d" % (isvsvn))

    (flags, flagmask , xfrms, miscs) = get_enclave_attributes(cmdline_args)

    # field format: (offset, type, value)
    sigstruct = {}
    sigstruct['header']    = (   0, "<4L",  *SIGSTRUCT_HEADER)
    sigstruct['vendor']    = (  16, "<L",   SIGSTRUCT_VENDOR)
    sigstruct['date']      = (  20, "<HBB", today.year, today.month, today.day)
    sigstruct['header2']   = (  24, "<4L",  *SIGSTRUCT_HEADER2)
    sigstruct['swdefined'] = (  40, "<L",   SIGSTRUCT_SWDEFINED)

    sigstruct['miscs']     = ( 900, "4s",   miscs)
    sigstruct['miscmask']  = ( 904, "4s",   miscs)
    sigstruct['attrs']     = ( 928, "8s8s", flags, xfrms)
    sigstruct['attrmask']  = ( 944, "8s8s", flagmask, xfrms)
    sigstruct['mrenclave'] = ( 960, "32s",  mrenclave)
    sigstruct['isvprodid'] = (1024, "<H",   isvprodid)
    sigstruct['isvsvn']    = (1026, "<H",   isvsvn)

    return sigstruct

# This modifies the sigstruct argument
def update_sigstruct(cmdline_args, sigstruct):
    today = datetime.date.today()

    if cmdline_args.isvprodid is not None:
        sigstruct['isvprodid'] = (1024, "<H", cmdline_args.isvprodid)

    if cmdline_args.isvsvn is not None:
        sigstruct['isvsvn'] = (1026, "<H", cmdline_args.isvsvn)

    (flags, flagmask , xfrms, miscs) = get_enclave_attributes(cmdline_args)


    # field format: (offset, type, value)
    sigstruct['date']      = (  20, "<HBB", today.year, today.month, today.day)

    sigstruct['miscs']     = ( 900, "4s",   miscs)
    sigstruct['miscmask']  = ( 904, "4s",   miscs)
    sigstruct['attrs']     = ( 928, "8s8s", flags, xfrms)
    sigstruct['attrmask']  = ( 944, "8s8s", flagmask, xfrms)

    return sigstruct

def read_sigstruct(f):
    buf = f.read()
    if len(buf) != SIGSTRUCT_LEN:
        raise ValueError('Invalid sigstruct length {}'.format(len(buf)))

    fields = {}
    fields['header']    = (   0, "<4L")
    fields['vendor']    = (  16, "<L")
    fields['date']      = (  20, "<HBB")
    fields['header2']   = (  24, "<4L")
    fields['swdefined'] = (  40, "<L")

    fields['miscs']     = ( 900, "4s")
    fields['miscmask']  = ( 904, "4s")
    fields['attrs']     = ( 928, "8s8s")
    fields['attrmask']  = ( 944, "8s8s")
    fields['mrenclave'] = ( 960, "32s")
    fields['isvprodid'] = (1024, "<H")
    fields['isvsvn']    = (1026, "<H")

    sigstruct = {}
    for key, field in fields.items():
        sigstruct[key] = (*field, *struct.unpack_from(field[1], buf, offset=field[0]))

    # Check some fixed fields
    if sigstruct['header'][2:] != SIGSTRUCT_HEADER:
        raise ValueError('Invalid sigstruct header {}'.format(sigstruct['header']))
    if sigstruct['vendor'][2:] != (SIGSTRUCT_VENDOR,):
        raise ValueError('Invalid sigstruct vendor {}'.format(sigstruct['vendor']))
    if sigstruct['header2'][2:] != SIGSTRUCT_HEADER2:
        raise ValueError('Invalid sigstruct header2 {}'.format(sigstruct['header2']))
    if sigstruct['swdefined'][2:] != (SIGSTRUCT_SWDEFINED,):
        raise ValueError('Invalid sigstruct swdefined {}'.format(sigstruct['swdefined']))

    return sigstruct

# Note that this modifies the `sigstruct` argument.
def sign_sigstruct(signer, sigstruct):
    sign_buffer = bytearray(128 + 128)

    for key, field in sigstruct.items():
        if field[0] >= 900:
            struct.pack_into(field[1], sign_buffer, field[0] - 900 + 128, *field[2:])
        else:
            struct.pack_into(field[1], sign_buffer, field[0], *field[2:])

    (signature, modulus) = signer.sign(sign_buffer)

    signature_int = int.from_bytes(signature, byteorder='big')

    tmp1   = signature_int * signature_int
    q1_int = tmp1 // modulus
    tmp2   = tmp1 % modulus
    q2_int = tmp2 * signature_int // modulus

    # In the unlikely event SGX_SIGNING_KEY_MODULUS_LEN changes, this would
    # need to be updated.
    q1 = q1_int.to_bytes(384, byteorder='little')
    q2 = q2_int.to_bytes(384, byteorder='little')

    sigstruct['modulus']   = ( 128, "384s", modulus.to_bytes(384, byteorder='little'))
    sigstruct['exponent']  = ( 512, "<L",   SGX_SIGNING_KEY_EXPONENT)
    sigstruct['signature'] = ( 516, "384s", signature[::-1])

    sigstruct['q1']        = (1040, "384s", q1)
    sigstruct['q2']        = (1424, "384s", q2)

    buffer = bytearray(SIGSTRUCT_LEN)

    for key, field in sigstruct.items():
        struct.pack_into(field[1], buffer, field[0], *field[2:])

    return buffer

""" Main Program """

def parse_args():
    # Single-hyphen versions of some arguments are preserved for backwards
    # compatibility. New arguments can allow double-hyphen only.
    parser = argparse.ArgumentParser(description="Generate manifest signature")
    parser.add_argument('-output', required=True, help='Output filename')
    parser.add_argument('-libpal', help='Path to libpal shared library')
    parser.add_argument('-manifest', help='Path to manifest file')
    parser.add_argument('-exec', help='Path to executable', dest='executable')
    parser.add_argument('--isvsvn', help='Security release number', type=unsigned_short, default=None, dest='isvsvn')
    parser.add_argument('--isvprodid', help='Product id', type=unsigned_short, default=None, dest='isvprodid')
    parser.add_argument('-verbose', action='store_true',
                        help='Print verbose output during signing')
    parser.add_argument('--container',
                        help='Take files from this container instead of the host (except for the manifest)')
    parser.add_argument('--keep-temp-dirs', help='Keep temporary directories instead of deleting', action='store_true')
    parser.add_argument('--plugin-id', help='UUID of SDKMS sign+log plugin')
    parser.add_argument('--build-info', help='File containing build information for SDKMS plugin signing',
                        type=argparse.FileType('r', encoding='utf-8'))
    parser.add_argument('--production', help='Sign a production enclave (ATTRIBUTES.DEBUG = 0)', action='store_true')
    key_group = parser.add_mutually_exclusive_group(required=True)
    key_group.add_argument('-key', '--key', help='Path to PEM-format signing key')
    key_group.add_argument('--sdkms-key', help='Name of SDKMS signing key. FORTANIX_API_KEY must be set in the environment.')

    args = parser.parse_args()
    if args.verbose:
        global verbose
        verbose = args.verbose

    if args.build_info and not args.plugin_id:
        raise ValueError('--build-info does not make sense without --plugin-id')

    return args

# Stand-in for the tempfile.TemporaryDirectory() class in case we want to
# preserve temporary directories after the script run.
class SavedTempDir(object):
    def __init__(self, name):
        self.name = name

    def cleanup(self):
        pass

def make_temp_dir(keep_temp_dirs):
    if keep_temp_dirs:
        ret = SavedTempDir(tempfile.mkdtemp(prefix='signer-'))
        print("Using temporary directory {}".format(ret.name))
        return ret
    else:
        return tempfile.TemporaryDirectory(prefix='signer-')

# The LocalFileReader and DockerFileReader classes provide interfaces for accessing files from the local
# filesystem and from inside a docker container, respectively.
class LocalFileReader(object):
    def __init__(self):
        pass

    def get_file(self, filename):
        return filename

    def get_runtime_path(self):
        return os.environ.get("ENCLAVEOS_RUNTIME",
                              "/opt/fortanix/enclave-os")

    def exists(self, filename):
        return os.path.exists(filename)

class DockerFileReader(object):
    def __init__(self, container, tmpdir):
        self.container = container
        self.tmpdir = tmpdir

    # TODO: We may need to support a different maximum link depth. A cursory google search indicates that
    # the maximum link depth is 40 for modern Linux kernels.
    def get_file(self, filename, maxdepth=16):
        debug_print('Reading file {} from container'.format(filename))
        origfile = filename
        while maxdepth > 0:
            maxdepth -= 1
            (fd, name) = tempfile.mkstemp(prefix='signer-', dir=self.tmpdir)
            (contents, attributes) = self.container.get_archive(filename)

            # TODO: It seems like there should be a way to do this without copying into a BytesIO.
            archive = io.BytesIO()
            shutil.copyfileobj(contents, archive)
            archive.seek(0, io.SEEK_SET)

            tar = tarfile.open(mode='r', fileobj=archive)
            f_info = tar.getmember(os.path.basename(filename))
            if f_info.type == tarfile.REGTYPE or f_info.type == tarfile.AREGTYPE:
                debug_print('Resolved file {} as {}'.format(origfile, filename))
                f = tar.extractfile(os.path.basename(filename))
                with os.fdopen(fd, 'wb') as fh:
                    shutil.copyfileobj(f, fh)

                return name
            elif f_info.type == tarfile.SYMTYPE:
                # The file was a symbolic link. We have to resolve these ourselves.
                newfile = os.path.join(os.path.dirname(filename), f_info.linkname)
                debug_print('Resolving symlink {} -> {}'.format(filename, newfile))
                filename = newfile
                continue
            else:
                raise ValueError('Unable to read file of type {}'.format(f_info.type))
        raise ValueError('Too many symbol links trying to resolve file {}'.format(origfile))

    # When we're signing a container, the runtime files will always be in the runtime location.
    def get_runtime_path(self):
        return "/opt/fortanix/enclave-os"

    # TODO: Implement this function to actaully do something. For now, we'll fail later trying to access the
    # actual file if it does not exist.
    def exists(self, filename):
        return True

def sign_manifest():
    # Parse arguments
    cmdline_args = parse_args()

    docker_client = None
    container = None
    oldsig = None
    tempdir = make_temp_dir(cmdline_args.keep_temp_dirs)
    if cmdline_args.container:
        docker_client = docker.from_env()
        container = docker_client.containers.create(cmdline_args.container)
        reader = DockerFileReader(container, tempdir.name)
        oldsig = get_sig(container)
    else:
        reader = LocalFileReader()
        container = None

    try:
        if oldsig is None:
            if cmdline_args.libpal is None or cmdline_args.manifest is None:
                raise ValueError('the following arguments are required for sigstruct generation: -libpal, -manifest')

            sign_manifest_helper(cmdline_args, container, reader, tempdir.name)
        else:
            sign_container(cmdline_args, docker_client, container, reader)
    finally:
        if container:
            container.remove(v=True)

def copy_libpal(tempdir, reader, libpal_path):
    copied_libpal = os.path.join(tempdir, os.path.basename(libpal_path))
    shutil.copyfile(reader.get_file(libpal_path), copied_libpal)
    return copied_libpal

def customize_libpal(copied_libpal, enclave_size, libpal_load_addr, manifest_base_addr, manifest_size, vdso_base,
                     vdso_size, shim_base, shim_size):
    # There should be only one data segment in the PAL.
    loadcmds = get_loadcmds(copied_libpal)
    data_segment_offset = None
    data_segment_addr = None
    for (offset, addr, filesize, memsize, prot) in loadcmds:
        if (prot == 6):
            assert(data_segment_offset is None)
            data_segment_offset = offset
            data_segment_addr = addr

    assert data_segment_offset is not None

    # The enclave_parameters structure must be at the very beginning of the
    # data segment.
    with open(copied_libpal, 'rb+') as fh:
        fh.seek(data_segment_offset)
        # TODO: We don't currently have a way to pick up the structure
        # definition here from the pal-loader.h C header file. They must be
        # kept in sync manually.
        data = fh.read(0x50)
        (orig_size, orig_base, orig_pal_base, orig_manifest_base_addr, orig_manifest_size, orig_vdso_base,
         orig_vdso_size, orig_shim_base, orig_shim_size, orig_ssa_size) = \
            struct.unpack('<QQQQQQQQQQ', data)

        # "Fortanix" in ASCII.
        magic = 0x78696e6174726f46
        assert(orig_size == magic)
        assert(orig_base == magic)
        assert(orig_pal_base == magic)
        assert(orig_manifest_base_addr == magic)
        assert(orig_manifest_size == magic)
        assert(orig_vdso_base == magic)
        assert(orig_vdso_size == magic)
        assert(orig_shim_base == magic)
        assert(orig_shim_size == magic)
        assert(orig_ssa_size == magic)

        fh.seek(data_segment_offset)
        enclave_base = 0
        fh.write(struct.pack('<QQQQQQQQQQ', enclave_size + enclave_base, enclave_base, libpal_load_addr,
                             manifest_base_addr, manifest_size, vdso_base, vdso_size, shim_base, shim_size,
                             SSAFRAMESIZE))

    return copied_libpal

def get_area_by_name(memory_areas, name):
    for area in memory_areas:
        if area.desc == name:
            return area

    assert(0)

def get_load_addr_by_name(memory_areas, name):
    area = get_area_by_name(memory_areas, name)
    return int(area.addr)

def get_size_by_name(memory_areas, name):
    area = get_area_by_name(memory_areas, name)
    return int(area.size)

def set_contents_by_name(memory_areas, name, contents):
    area = get_area_by_name(memory_areas, name)
    area.contents = contents

def get_vdso_path(manifest, reader):
    if 'loader.vdso' in manifest:
        vdso = manifest['loader.vdso']
        if vdso == 'none':
            return None
        if vdso.startswith('file:'):
            return reader.get_file(vdso[5:])
        else:
            raise RuntimeError('Invalid URI type for vdso: {}'.format(vdso))
    else:
        return reader.get_file(os.path.join(reader.get_runtime_path(), "bootstrap",
                                            "libenclaveos-vdso.so"))

def get_shim_path(manifest, reader):
    if 'loader.preload' in manifest:
        if manifest['loader.preload'].startswith('file:'):
            return manifest['loader.preload'][5:]
        else:
            raise RuntimeError('Invalid URI for loader.preload: {}'.format(manifest['loader.preload']))

    if 'loader.preload_shim' in manifest and not manifest['loader.preload_shim']:
        return None

    return reader.get_file(os.path.join(reader.get_runtime_path(), "bootstrap",
                                        "libenclaveos-interface.so"))

# Generate an SGX manifest, construct an SGX SIGSTRUCT, and sign it. The SGX
# manifest is based on the input manifest and adds trusted file hashes. The
# SIGSTRUCT reflects the manifest and other items loaded into the enclave
# at runtime.
#
# This routine writes the SGX manifest to a file specified with -output on
# the command line, and writes the sigstruct to a filename derived from
# the manifest name (e.g. for app.manifest.sgx, writes to app.sig).
def sign_manifest_helper(cmdline_args, container, reader, tempdir):
    executable = cmdline_args.executable
    (manifest, manifest_layout) = read_manifest(cmdline_args.manifest)

    if 'sgx.sigfile' in manifest:
        sigfile = resolve_uri(manifest['sgx.sigfile'], LocalFileReader(), False)
    else:
        sigfile = cmdline_args.output
        for ext in ['.manifest.sgx', '.manifest']:
            if sigfile.endswith(ext):
                sigfile = sigfile[:-len(ext)]
                break
        sigfile = sigfile + '.sig'
        manifest['sgx.sigfile'] = 'file:' + os.path.basename(sigfile)

    # Get enclave size and thread count from manifest
    if 'sgx.enclave_size' not in manifest:
        manifest['sgx.enclave_size'] = DEFAULT_ENCLAVE_SIZE
    enclave_size = parse_size(manifest['sgx.enclave_size'])

    if 'sgx.thread_num' not in manifest:
        manifest['sgx.thread_num'] = str(DEFAULT_THREAD_NUM)
    thread_num = parse_int(manifest['sgx.thread_num'])

    # We used to support setting these SIGSTRUCT values via the manifest, but
    # now we only accept them on the command line. This can be removed at some
    # point, it is unlikely there is anything trying to use these.
    for key in ['isvprodid', 'isvsvn', 'debug', 'enable_avx3', 'enable_mpx', 'support_exinfo']:
        if key in manifest:
            raise ValueError('Manifest option sgx.{} is no longer supported'.format(key))

    # Get trusted checksums and measurements
    debug_print("Trusted files:")
    for key, val in get_trusted_files(manifest, executable, reader).items():
        (uri, target, checksum) = val
        debug_print("    %s %s" % (checksum, uri))
        manifest['sgx.trusted_checksum.' + key] = checksum.decode('utf-8')

    debug_print("Trusted children:")
    for key, val in get_trusted_children(manifest).items():
        (uri, target, mrenclave) = val
        debug_print("    %s %s" % (mrenclave, uri))
        manifest['sgx.trusted_mrenclave.' + key] = mrenclave.decode('utf-8')

    copied_pal = copy_libpal(tempdir, reader, cmdline_args.libpal)

    vdso_path = get_vdso_path(manifest, reader)
    shim_path = get_shim_path(manifest, reader)

    # Try populate memory areas
    (memory_areas, stacks) = get_memory_areas(manifest, thread_num, copied_pal, vdso_path, shim_path)

    if len([a for a in memory_areas if a.addr is not None]) > 0:
        manifest['sgx.static_address'] = '1'

    # Add manifest at the top
    shutil.copy2(cmdline_args.manifest, cmdline_args.output)
    output_manifest(cmdline_args.output, manifest, manifest_layout)

    manifest_size = os.stat(cmdline_args.output).st_size
    memory_areas = [
            MemoryArea('manifest', file=cmdline_args.output,
                       flags=PAGEINFO_R|PAGEINFO_REG, eextend=True)
            ] + memory_areas

    memory_areas = populate_memory_areas(manifest, enclave_size, memory_areas)
    entry = get_entry_point(copied_pal)

    libpal_load_addr = get_load_addr_by_name(memory_areas, 'pal')
    manifest_base_addr = get_load_addr_by_name(memory_areas, 'manifest')
    tls_load_addr = get_load_addr_by_name(memory_areas, 'tls')
    ssa_load_addr = get_load_addr_by_name(memory_areas, 'ssa')

    tcs_contents = create_tcs(ssa_load_addr, tls_load_addr, libpal_load_addr, entry, thread_num)
    set_contents_by_name(memory_areas, 'tcs', tcs_contents)

    tls_contents = create_tls(tls_load_addr, stacks, ssa_load_addr, thread_num)
    set_contents_by_name(memory_areas, 'tls', tls_contents)

    if vdso_path is None:
        vdso_base = 0xffffffffffffffff
        vdso_size = 0
    else:
        vdso_base = get_load_addr_by_name(memory_areas, 'vdso')
        vdso_size = get_size_by_name(memory_areas, 'vdso')
    if shim_path is None:
        shim_base = 0xffffffffffffffff
        shim_size = 0
    else:
        shim_base = get_load_addr_by_name(memory_areas, 'shim')
        shim_size = get_size_by_name(memory_areas, 'shim')

    customize_libpal(copied_pal, enclave_size, libpal_load_addr, manifest_base_addr, manifest_size, vdso_base,
                     vdso_size, shim_base, shim_size)

    debug_print("Memory:")
    # Generate measurement
    mrenclave = generate_measurement(enclave_size, memory_areas)

    debug_print("Measurement:")
    debug_print(b"    " + binascii.hexlify(mrenclave))

    signer = get_signer(cmdline_args)
    sigstruct = fill_sigstruct(cmdline_args, mrenclave)
    open(sigfile, 'wb').write(sign_sigstruct(signer, sigstruct))

def get_sig(container):
    if 'Env' in container.attrs['Config']:
        for var in container.attrs['Config']['Env']:
            if var.startswith('ENCLAVEOS_SIGNATURE='):
                return base64.b64decode(var[20:])
    return None

# Read an existing SIGSTRUCT from a container, resign it, and build a new
# docker image with the new signature. This is useful for applying
# production signatures to images.
#
# Note that unlike sign_manifest_helper, output in this case is a docker
# image held by the local docker daemon.
def sign_container(cmdline_args, docker_client, container, reader):
    oldsig = get_sig(container)
    if oldsig is None:
        raise ValueError('Container does not have the ENCLAVEOS_SIGNATURE environment variable')
    sigstruct = read_sigstruct(io.BytesIO(oldsig))

    # Modifies the sigstruct argument based on cmdline args
    update_sigstruct(cmdline_args, sigstruct)

    signer = get_signer(cmdline_args)
    newsig = sign_sigstruct(signer, sigstruct)

    dockerfile = io.BytesIO()
    dockerfile.write(('FROM {}\n'.format(cmdline_args.container)).encode('utf-8'))
    dockerfile.write('ENV {} "{}"\n'.format("ENCLAVEOS_SIGNATURE",
                                            base64.b64encode(newsig).decode('utf-8')).encode('utf-8'))
    dockerfile.seek(0, io.SEEK_SET)

    final_image = docker_client.images.build(fileobj=dockerfile, rm=True)

    (repo, tag) = IMAGE_REGEX.match(cmdline_args.output).groups()
    final_image.tag(repo, tag)

if __name__ == "__main__":
    sign_manifest()
